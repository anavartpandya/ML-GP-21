{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "METIS_ML_FINAL.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3awrJnv3Nc6U"
      },
      "source": [
        "This the main notebook that is to be run by the user. First run all the cells and then run the last cell each time to search for a particular movie and get recommendation based on your selected movie.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cjroxNgiTsu_"
      },
      "source": [
        "NOTE: YOU NEED TO MOUNT THE GOOGLE DRIVE BEFORE USING THIS NOTEBOOK\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U_unpJ_iQmZH"
      },
      "source": [
        "Install the word2number library"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VF3SP-LLL2-u",
        "outputId": "4a54ef28-fa5f-43a5-fb88-a34a88cafddc"
      },
      "source": [
        "pip install word2number"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: word2number in /usr/local/lib/python3.7/dist-packages (1.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6KFw9dD7H3Le"
      },
      "source": [
        "#import all the necessary libraries for this notebook.\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from word2number import w2n\n",
        "from time import sleep\n",
        "from IPython.display import clear_output"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q6iM-N-YIAN1"
      },
      "source": [
        "#import all the excel data files that are necessary for this notebook as dataframes.\n",
        "\n",
        "df = pd.read_excel('/content/drive/MyDrive/ml-25m/movies.xlsx')   #reading the movies data file provided in the original dataset.\n",
        "df1 = pd.read_excel('/content/drive/MyDrive/ml-25m/ratings.xlsx')   #reading the ratings data file provided in the original dataset.\n",
        "sdsd= pd.read_excel(\"/content/drive/MyDrive/ml-25m/genome-scores.xlsx\")   #reading the genome-scores data file provided in the original dataset.\n",
        "asas = pd.read_excel(\"/content/drive/MyDrive/ml-25m/genome-tags.xlsx\")    #reading the genome-tags data file provided in the original dataset.\n",
        "df2 = pd.read_excel(\"/content/drive/MyDrive/ml-25m/Copy of genre_clusters.xlsx\")    #reading the genre_clusters data file that has been preprocessed and contains the cluster group information of each movie of the given dataset."
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wmrULZQOVkGH"
      },
      "source": [
        "#load all the pre-processed matrices processed by the singular value decomposition method (svd).\n",
        "#The movies in the data set are divided into 9 clusters and each cluster has its unique svd matrix which are loaded below.\n",
        "#This matrices are in the form of numpy arrays.\n",
        "\n",
        "V1a = np.load('/content/drive/MyDrive/ml-25m/V_data/V1a.npy')\n",
        "V1b = np.load('/content/drive/MyDrive/ml-25m/V_data/V1b.npy')\n",
        "V1c = np.load('/content/drive/MyDrive/ml-25m/V_data/V1c.npy')\n",
        "V2a = np.load('/content/drive/MyDrive/ml-25m/V_data/V2a.npy')\n",
        "V2b = np.load('/content/drive/MyDrive/ml-25m/V_data/V2b.npy')\n",
        "V2c = np.load('/content/drive/MyDrive/ml-25m/V_data/V2c.npy')\n",
        "V3a = np.load('/content/drive/MyDrive/ml-25m/V_data/V3a.npy')\n",
        "V3b = np.load('/content/drive/MyDrive/ml-25m/V_data/V3b.npy')\n",
        "V3c = np.load('/content/drive/MyDrive/ml-25m/V_data/V3c.npy')"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mZeMhNXrI-eo"
      },
      "source": [
        "#Create list of movies present in each movie cluster.\n",
        "\n",
        "lst1a=[]\n",
        "for i in df2[df2['Clusters'] == '1a']['MovieId']:\n",
        "  lst1a.append(i)                                 #creates list of all movies present in cluster group 1a. \n",
        "lst1b=[]\n",
        "for i in df2[df2['Clusters'] == '1b']['MovieId']:\n",
        "  lst1b.append(i)                                 #creates list of all movies present in cluster group 1b.                                         \n",
        "lst1c=[]\n",
        "for i in df2[df2['Clusters'] == '1c']['MovieId']:\n",
        "  lst1c.append(i)                                 #creates list of all movies present in cluster group 1c.\n",
        "lst2a=[]\n",
        "for i in df2[df2['Clusters'] == '2a']['MovieId']:\n",
        "  lst2a.append(i)                                 #creates list of all movies present in cluster group 2a.\n",
        "lst2b=[]\n",
        "for i in df2[df2['Clusters'] == '2b']['MovieId']:\n",
        "  lst2b.append(i)                                 #creates list of all movies present in cluster group 2b.\n",
        "lst2c=[]\n",
        "for i in df2[df2['Clusters'] == '2c']['MovieId']:\n",
        "  lst2c.append(i)                                 #creates list of all movies present in cluster group 2c.\n",
        "lst3a=[]\n",
        "for i in df2[df2['Clusters'] == '3a']['MovieId']:\n",
        "  lst3a.append(i)                                 #creates list of all movies present in cluster group 3a.\n",
        "lst3b=[]\n",
        "for i in df2[df2['Clusters'] == '3b']['MovieId']:\n",
        "  lst3b.append(i)                                 #creates list of all movies present in cluster group 3b.\n",
        "lst3c=[]\n",
        "for i in df2[df2['Clusters'] == '3c']['MovieId']:\n",
        "  lst3c.append(i)                                 #creates list of all movies present in cluster group 3c."
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d6adXLEVE8Fc"
      },
      "source": [
        "#Build a function that provides a bunch of similar movies based on the input movie. \n",
        "\n",
        "def movie_recommend(id):          #the function takes only one argument which is the movie Id.\n",
        "  lst = []\n",
        "  for i in df2[df2['MovieId']==id].Clusters:\n",
        "    cls = i                       #finding the cluster group of the input movie Id.\n",
        " \n",
        "  if cls == '1a':                 #Finding the svd matrix corresponding to the cluster group (to which the movie Id belongs) for further processing.\n",
        "    V = V1a\n",
        "    lst = lst1a\n",
        "  elif cls == '1b':\n",
        "    V = V1b\n",
        "    lst = lst1b\n",
        "  elif cls == '1c':\n",
        "    V = V1c\n",
        "    lst = lst1c\n",
        "  elif cls == '2a':\n",
        "    V = V2a\n",
        "    lst = lst2a\n",
        "  elif cls == '2b':\n",
        "    V = V2b\n",
        "    lst = lst2b\n",
        "  elif cls == '2c':\n",
        "    V = V2c\n",
        "    lst = lst2c\n",
        "  elif cls == '3a':\n",
        "    V = V3a\n",
        "    lst = lst3a\n",
        "  elif cls == '3b':\n",
        "    V = V3b\n",
        "    lst = lst3b\n",
        "  elif cls == '3c':\n",
        "    V = V3c\n",
        "    lst = lst3c\n",
        "\n",
        "  #The movie Ids are not uniform by numbering. Some movie Ids are missing in the original dataset.\n",
        "\n",
        "  #So to make the numbering uniform, a dictionary is made where the key is the original movie Id and its value is\n",
        "  #the new uniformly numbered movie Id.\n",
        "\n",
        "  asdf = {}\n",
        "  for i in range(len(lst)):\n",
        "    asdf[lst[i]] = i\n",
        "\n",
        "  #defining the get_key function which enables us to get the key from the value of a dictionary.\n",
        "\n",
        "  def get_key(dict, val):           #the function takes dictionary name as the first argument and value of a particular key in that dictionary as the second argument.\n",
        "    for key, value in dict.items():\n",
        "         if val == value:\n",
        "             return key             #the function returns the key corresponding to the input dictionary and the value.\n",
        "\n",
        "  #defining the cosine similarity function to get the top similar movie by applying the cosine similarity between two arrays.\n",
        "  def top_cosine_similarity(data, movie_id, top_n):  #the function takes the svd data matrix/array as the first argument, movie Id as the second argument and how many top movies to return as the third argument.\n",
        "      index = asdf[movie_id]\n",
        "      movie_row = data[index, :]\n",
        "      magnitude = np.sqrt(np.einsum('ij, ij -> i', data, data)) \n",
        "      similarity = np.dot(movie_row, data.T) / (magnitude[index] * magnitude)\n",
        "      sort_indexes = np.argsort(-similarity)\n",
        "      return sort_indexes[:top_n]   #the function returns an array containing new movie Ids of the top n similar movies.\n",
        "\n",
        "  #now we will use the top_cosine_similarity function and print the movies using the movie Id present in the array that is returned by the top_cosine_similarity func.\n",
        "\n",
        "  #printing the details of the movie which is inputed.\n",
        "  movie_id = id\n",
        "  print('your movie:\\n')\n",
        "  for i in df[df.movieId==movie_id].title:\n",
        "    print(i)\n",
        "  for j in df[df.movieId==movie_id].genres:\n",
        "    print(j + '\\n')\n",
        "\n",
        "  top_n = 20                                                        #defining the number of movies to be recommended.\n",
        "  sliced_matrix = V.T                                               #defining the svd data matrix that is to be provided as an argument to the top_cosine_similarity function.\n",
        "  indexes = top_cosine_similarity(sliced_matrix, movie_id, top_n)    #use the top_cosine_similarity function.\n",
        " \n",
        "  #print recommended movies.\n",
        "  if len(indexes) > 0:\n",
        "    print('Movies You may like:\\n')\n",
        "    for i in indexes:\n",
        "      for j in df[df.movieId==get_key(asdf,i)].title:\n",
        "        print(j)\n",
        "      for j in df[df.movieId==get_key(asdf,i)].genres:\n",
        "        print(j + '\\n')"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "78dmSjJrINhX"
      },
      "source": [
        "#Build a function that returns movies that are relevant to the input tag.\n",
        "\n",
        "tag_movie_dict = {}                   #building a dictionary that has tag id as the key and list of all the movies (whose relevance with the tag id is greater than or equal to 0.5) as the value.\n",
        "sdsd1 = sdsd[sdsd[\"relevance\"] >= 0.5]\n",
        "for i in range(len(asas)):\n",
        "    sdsd2 = sdsd1[sdsd1[\"tagId\"]==i+1]\n",
        "    sdsds2 = sdsd2.sort_values('relevance', ascending=False)\n",
        "    tag_movie_dict[i+1] = list(sdsds2[\"movieId\"])\n",
        "\n",
        "  \n",
        "def movie_tagbased(a, check):        #the function takes the input tag as first argument and check (either 0 or 1) as the second argument. The function will print anything only if the check is equal to 1, else it will only return the desired value. \n",
        "  try:\n",
        "      b = int(asas[asas[\"tag\"] == a][\"tagId\"])\n",
        "      if len(tag_movie_dict[b]) <= 10:\n",
        "        for i in range(len(tag_movie_dict[b])):\n",
        "          c = list(df[df[\"movieId\"] == tag_movie_dict[b][i]][\"title\"])\n",
        "          for j in c:\n",
        "            if check == 1:\n",
        "              print(str(i+1) + \" \" + j)\n",
        "        if check == 1:\n",
        "          print('')\n",
        "          print('enter the number in front of the movie to watch the movie')\n",
        "          input1 = int(input())-1\n",
        "          clear_output()             #clears the screen (NOTE: This code is IDE specific and is only valid for google colab notebook)\n",
        "          movie_recommend(int((tag_movie_dict[b])[input1]))\n",
        "      else:\n",
        "        for i in range(len((tag_movie_dict[b])[:10])):\n",
        "          c = list(df[df[\"movieId\"] == (tag_movie_dict[b][:10])[i]][\"title\"])\n",
        "          for j in c:\n",
        "            if check == 1:\n",
        "              print(str(i+1) + \" \" + j)\n",
        "        if check == 1:\n",
        "          print()\n",
        "          print('enter m for more suggestions')\n",
        "          print('or enter the number in front of the movie to watch the movie')\n",
        "          input1 = input()\n",
        "          if input1 == 'm':\n",
        "            for i in range(len((tag_movie_dict[b])[10:])):\n",
        "              c = list(df[df[\"movieId\"] == (tag_movie_dict[b][10:])[i]][\"title\"])\n",
        "              for j in c:\n",
        "                print(str(i+1+10) + \" \" + j)\n",
        "            print('enter the number in front of the movie to watch the movie')\n",
        "            input2  = int(input())-1\n",
        "            clear_output()          #clears the screen\n",
        "            movie_recommend(int((tag_movie_dict[b])[input2]))            \n",
        "          else:\n",
        "              clear_output()        #clears the screen\n",
        "              movie_recommend(int((tag_movie_dict[b])[int(input1)-1]))       \n",
        "  except:\n",
        "      return(\"no such movies found\")"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xLICsWsTI_IM"
      },
      "source": [
        "#defining the get_key function to get the key from the value.\n",
        "def get_key(dict, val):                   #the function takes dictionary name as the first argument and value of a particular key in that dictionary as the second argument.\n",
        "    for key, value in dict.items():\n",
        "         if val == value:\n",
        "             return key                   #the function returns the key corresponding to the input dictionary and the value.\n",
        "\n",
        "#building a function that returns the movies based on the names seached in search box.\n",
        "def movie_namebased(user_input, check):   #the function takes user input as the first argument and check as the second argument. The role of check is the same as it is in movie_tagbased function.\n",
        "  movie_list = [user_input]\n",
        "\n",
        "  for i in df[\"title\"]:\n",
        "      movie_list.append(i)\n",
        "\n",
        "  #using the tensorflow tokenizer to tokenize each word in the movie data set.\n",
        "  tokenizer = Tokenizer()                 \n",
        "  tokenizer.fit_on_texts(movie_list)\n",
        "  index = tokenizer.word_index\n",
        "  sequences = tokenizer.texts_to_sequences(movie_list) #creating sequences of the tokens created.\n",
        "\n",
        "  l = user_input.split()\n",
        "  l1 = []\n",
        "  l3 = []\n",
        "  for k in l:\n",
        "      l2 = []\n",
        "      try:\n",
        "          v = [k, str(w2n.word_to_num(k))]\n",
        "      except:\n",
        "          v = [k]\n",
        "      for i in v:\n",
        "          for j in range(len(sequences)):\n",
        "              if j > 0:\n",
        "                  if index[i] in sequences[j]:\n",
        "                      s = \"\"\n",
        "                      l2.append(movie_list[j])\n",
        "                      for k in sequences[j]:\n",
        "                          s = s + \" \" + get_key(index, k)\n",
        "                      l1.append(s[1:][:len(s)-6])\n",
        "      l3.append(l2)\n",
        "  l4 = set.intersection(*[set(list) for list in l3])\n",
        "  l5 = []\n",
        "  for i in l3:\n",
        "    for j in i:\n",
        "      l5.append(j)\n",
        "  if l5 == []:\n",
        "    ret1 = \"no searches found\"\n",
        "  else:\n",
        "    ret1 = None\n",
        "    if check == 1:\n",
        "      if l4 != set():\n",
        "        dict_m = {}\n",
        "        for i in range(len(l4)):\n",
        "          print(str(i+1) + ' ' + (list(l4))[i])\n",
        "          dict_m[i+1] = (list(l4))[i]\n",
        "        print(\"\\n\")\n",
        "        jcount = 0\n",
        "        if len(l5) != len(list(l4)):\n",
        "          print('Similar Results:')\n",
        "        for j in range(len(l5)):\n",
        "          if l5[j] not in l4:\n",
        "            jcount = jcount + 1\n",
        "            print(str(i+jcount+1) + \" \" + l5[j])\n",
        "            dict_m[i+jcount+1] = l5[j]\n",
        "      if l4 == set():\n",
        "        dict_m = {}\n",
        "        jcount = 1\n",
        "        print('Did you mean:')\n",
        "        print(str(jcount) + \" \" + l5[0] + '\\n')\n",
        "        dict_m[jcount] = l5[0]\n",
        "        if len(l5)>0:\n",
        "          print('Similar Results:')\n",
        "        for j in range(1,len(l5)):\n",
        "          if l5[j] not in l4:\n",
        "            jcount = jcount + 1\n",
        "            print(str(jcount) + \" \" + l5[j])  \n",
        "            dict_m[jcount] = l5[j]\n",
        "  if check == 0:\n",
        "    dict_m = None  \n",
        "    return([ret1, dict_m])\n",
        "  if check == 1:\n",
        "    return([ret1, dict_m])  "
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PGtuA6EtM7iK",
        "outputId": "adc7610a-d8d9-4896-d6ab-9a66a978fb73"
      },
      "source": [
        "#This is the final cell that will run everytime to search a movie or a tag.\n",
        "#This cell will run all the previously defined functions and return list of movies based on the search of the user and recommend some movies similar to the search\n",
        "\n",
        "#getting the user input.\n",
        "userinput = input()\n",
        "user_input = userinput.lower() #making the user input to lower case.\n",
        "\n",
        "clear_output()   #clear the screen\n",
        "\n",
        "#running previously defined functions for movie suggestions.\n",
        "if movie_tagbased(user_input, 0) == \"no such movies found\":\n",
        "  if (movie_namebased(user_input, 0))[0] == \"no searches found\":\n",
        "    print(\"no searches found\")\n",
        "  else:\n",
        "    resu = movie_namebased(user_input, 1)\n",
        "    print('\\nenter the number in front of the movie to watch the movie')\n",
        "    use_in = int(input())\n",
        "    clear_output()\n",
        "    for i in df[df['title'] == resu[1][use_in]]['movieId']:\n",
        "      movie_recommend(i)\n",
        "else:\n",
        "  movie_tagbased(user_input, 1)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "no searches found\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x--LpeIVqlXr"
      },
      "source": [
        "THE ABOVE CELL IS THE FINAL CELL. RUN IT EVERYTIME TO SEARCH AND MOVIE AND GET RECOMMENDATIONS BASED ON YOUR MOVIE."
      ]
    }
  ]
}